{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Custom code\n",
    "from src.load_data import load_data\n",
    "from src.custom_pipe import transform_pipeline, training_pipeline\n",
    "from src.finetuning import grid_search_best_estimator\n",
    "from src.predictions import generate_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, train_labels, test_values = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906               6             487           12198   \n",
       "1        28830               8             900            2812   \n",
       "2        94947              21             363            8973   \n",
       "3       590882              22             418           10694   \n",
       "4       201944              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "  land_surface_condition foundation_type  ... has_secondary_use_agriculture  \\\n",
       "0                      t               r  ...                             0   \n",
       "1                      o               r  ...                             0   \n",
       "2                      t               r  ...                             0   \n",
       "3                      t               r  ...                             0   \n",
       "4                      t               r  ...                             0   \n",
       "\n",
       "  has_secondary_use_hotel has_secondary_use_rental  \\\n",
       "0                       0                        0   \n",
       "1                       0                        0   \n",
       "2                       0                        0   \n",
       "3                       0                        0   \n",
       "4                       0                        0   \n",
       "\n",
       "  has_secondary_use_institution has_secondary_use_school  \\\n",
       "0                             0                        0   \n",
       "1                             0                        0   \n",
       "2                             0                        0   \n",
       "3                             0                        0   \n",
       "4                             0                        0   \n",
       "\n",
       "   has_secondary_use_industry  has_secondary_use_health_post  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   has_secondary_use_gov_office  has_secondary_use_use_police  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   has_secondary_use_other  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.606010e+05</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "      <td>260601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.256755e+05</td>\n",
       "      <td>13.900353</td>\n",
       "      <td>701.074685</td>\n",
       "      <td>6257.876148</td>\n",
       "      <td>2.129723</td>\n",
       "      <td>26.535029</td>\n",
       "      <td>8.018051</td>\n",
       "      <td>5.434365</td>\n",
       "      <td>0.088645</td>\n",
       "      <td>0.761935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.045450e+05</td>\n",
       "      <td>8.033617</td>\n",
       "      <td>412.710734</td>\n",
       "      <td>3646.369645</td>\n",
       "      <td>0.727665</td>\n",
       "      <td>73.565937</td>\n",
       "      <td>4.392231</td>\n",
       "      <td>1.918418</td>\n",
       "      <td>0.284231</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245426</td>\n",
       "      <td>0.180265</td>\n",
       "      <td>0.089638</td>\n",
       "      <td>0.030647</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.071364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.611900e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>3073.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.257570e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>6270.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.897620e+05</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>9412.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.052934e+06</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "count  2.606010e+05   260601.000000   260601.000000   260601.000000   \n",
       "mean   5.256755e+05       13.900353      701.074685     6257.876148   \n",
       "std    3.045450e+05        8.033617      412.710734     3646.369645   \n",
       "min    4.000000e+00        0.000000        0.000000        0.000000   \n",
       "25%    2.611900e+05        7.000000      350.000000     3073.000000   \n",
       "50%    5.257570e+05       12.000000      702.000000     6270.000000   \n",
       "75%    7.897620e+05       21.000000     1050.000000     9412.000000   \n",
       "max    1.052934e+06       30.000000     1427.000000    12567.000000   \n",
       "\n",
       "       count_floors_pre_eq            age  area_percentage  height_percentage  \\\n",
       "count        260601.000000  260601.000000    260601.000000      260601.000000   \n",
       "mean              2.129723      26.535029         8.018051           5.434365   \n",
       "std               0.727665      73.565937         4.392231           1.918418   \n",
       "min               1.000000       0.000000         1.000000           2.000000   \n",
       "25%               2.000000      10.000000         5.000000           4.000000   \n",
       "50%               2.000000      15.000000         7.000000           5.000000   \n",
       "75%               2.000000      30.000000         9.000000           6.000000   \n",
       "max               9.000000     995.000000       100.000000          32.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  ...  \\\n",
       "count                 260601.000000                        260601.000000  ...   \n",
       "mean                       0.088645                             0.761935  ...   \n",
       "std                        0.284231                             0.425900  ...   \n",
       "min                        0.000000                             0.000000  ...   \n",
       "25%                        0.000000                             1.000000  ...   \n",
       "50%                        0.000000                             1.000000  ...   \n",
       "75%                        0.000000                             1.000000  ...   \n",
       "max                        1.000000                             1.000000  ...   \n",
       "\n",
       "       has_secondary_use_agriculture  has_secondary_use_hotel  \\\n",
       "count                  260601.000000            260601.000000   \n",
       "mean                        0.064378                 0.033626   \n",
       "std                         0.245426                 0.180265   \n",
       "min                         0.000000                 0.000000   \n",
       "25%                         0.000000                 0.000000   \n",
       "50%                         0.000000                 0.000000   \n",
       "75%                         0.000000                 0.000000   \n",
       "max                         1.000000                 1.000000   \n",
       "\n",
       "       has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "count             260601.000000                  260601.000000   \n",
       "mean                   0.008101                       0.000940   \n",
       "std                    0.089638                       0.030647   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "count             260601.000000               260601.000000   \n",
       "mean                   0.000361                    0.001071   \n",
       "std                    0.018989                    0.032703   \n",
       "min                    0.000000                    0.000000   \n",
       "25%                    0.000000                    0.000000   \n",
       "50%                    0.000000                    0.000000   \n",
       "75%                    0.000000                    0.000000   \n",
       "max                    1.000000                    1.000000   \n",
       "\n",
       "       has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "count                  260601.000000                 260601.000000   \n",
       "mean                        0.000188                      0.000146   \n",
       "std                         0.013711                      0.012075   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                         1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_use_police  has_secondary_use_other  \n",
       "count                 260601.000000            260601.000000  \n",
       "mean                       0.000088                 0.005119  \n",
       "std                        0.009394                 0.071364  \n",
       "min                        0.000000                 0.000000  \n",
       "25%                        0.000000                 0.000000  \n",
       "50%                        0.000000                 0.000000  \n",
       "75%                        0.000000                 0.000000  \n",
       "max                        1.000000                 1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage_grade</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13243898715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77810839245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45936818526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              building_id\n",
       "damage_grade             \n",
       "1             13243898715\n",
       "2             77810839245\n",
       "3             45936818526"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.groupby('damage_grade').sum()\n",
    "# We see that there is a class imbalance in the labels. Depending on our desired final estimator, we may have to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features into those we want to encode, those we want to drop, and those we want to keep as they are\n",
    "\n",
    "columns_to_encode = [\n",
    "    'geo_level_1_id',\n",
    "    'land_surface_condition',\n",
    "    'foundation_type',\n",
    "    'roof_type',\n",
    "    'ground_floor_type',\n",
    "    'other_floor_type',\n",
    "    'position',\n",
    "    'plan_configuration',\n",
    "    'legal_ownership_status'\n",
    "    ]\n",
    "\n",
    "columns_to_drop = [\n",
    "    'building_id'\n",
    "    ]\n",
    "\n",
    "columns_to_keep_as_is = [\n",
    "    'geo_level_2_id',\n",
    "    'geo_level_3_id',\n",
    "    'count_floors_pre_eq',\n",
    "    'age',\n",
    "    'area_percentage',\n",
    "    'height_percentage',\n",
    "    'has_superstructure_adobe_mud',\n",
    "    'has_superstructure_mud_mortar_stone',\n",
    "    'has_superstructure_stone_flag',\n",
    "    'has_superstructure_cement_mortar_stone',\n",
    "    'has_superstructure_mud_mortar_brick',\n",
    "    'has_superstructure_cement_mortar_brick',\n",
    "    'has_superstructure_timber',\n",
    "    'has_superstructure_bamboo',\n",
    "    'has_superstructure_rc_non_engineered',\n",
    "    'has_superstructure_rc_engineered',\n",
    "    'has_superstructure_other',\n",
    "    'count_families',\n",
    "    'has_secondary_use',\n",
    "    'has_secondary_use_agriculture',\n",
    "    'has_secondary_use_hotel',\n",
    "    'has_secondary_use_rental',\n",
    "    'has_secondary_use_institution',\n",
    "    'has_secondary_use_school',\n",
    "    'has_secondary_use_industry',\n",
    "    'has_secondary_use_health_post',\n",
    "    'has_secondary_use_gov_office',\n",
    "    'has_secondary_use_use_police',\n",
    "    'has_secondary_use_other'\n",
    "    ]\n",
    "\n",
    "num_to_encode = list(columns_to_encode[0])\n",
    "cat_to_encode = columns_to_encode[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train_values[columns_to_encode],train_values[columns_to_keep_as_is]],axis=1)\n",
    "y = train_labels['damage_grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with three common classifiers for a problem like this: ```Logistic Regression```, ```Decision Tree Classifier``` and ```Random Forest Classifier```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(n_jobs=-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```preprocessor``` transforms the previously defined columns into one-hot-encoded features.\n",
    "The ```pipelines``` variables contains a dictionary with trained models. Scores are printed at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/luc/anaconda3/envs/dsr-b38/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy: 0.57 (+/- 0.01)\n",
      "DecisionTreeClassifier: Accuracy: 0.66 (+/- 0.00)\n",
      "RandomForestClassifier: Accuracy: 0.72 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = transform_pipeline(numerical_columns_to_encode=num_to_encode, categorical_columns_to_encode=cat_to_encode)\n",
    "pipelines = training_pipeline(estimators, preprocessor, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Finetuning with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__min_samples_split': [5, 10, 20],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__n_estimators': [10, 100, 500],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.705 total time=   0.9s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.707 total time=   1.0s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.721 total time=   5.2s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.722 total time=   5.4s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.723 total time=  10.0s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.724 total time=  10.1s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.723 total time=  25.1s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.724 total time=  25.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.710 total time=   0.9s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.712 total time=   0.9s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.723 total time=   5.2s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.725 total time=   5.2s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.724 total time=  10.1s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.726 total time=   9.7s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.724 total time=  24.4s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.725 total time=  24.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.711 total time=   0.9s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.714 total time=   1.0s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.720 total time=   4.7s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.723 total time=   5.0s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.721 total time=   9.1s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.724 total time=   9.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.722 total time=  23.7s\n",
      "[CV 2/2] END classifier__min_samples_leaf=1, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.724 total time=  22.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.709 total time=   1.0s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.710 total time=   1.0s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.718 total time=   5.0s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.720 total time=   5.3s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.719 total time=   9.3s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.721 total time=   9.1s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.719 total time=  22.5s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.721 total time=  23.2s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.708 total time=   0.8s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.713 total time=   0.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.717 total time=   5.0s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.720 total time=   4.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.717 total time=   8.9s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.719 total time=   8.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.718 total time=  21.5s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.720 total time=  21.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.708 total time=   0.8s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.709 total time=   0.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.715 total time=   4.6s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.717 total time=   4.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.716 total time=   8.5s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.717 total time=   8.8s\n",
      "[CV 1/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.716 total time=  20.6s\n",
      "[CV 2/2] END classifier__min_samples_leaf=2, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.718 total time=  21.9s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.703 total time=   0.9s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=10;, score=0.705 total time=   0.9s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.710 total time=   4.8s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=100;, score=0.713 total time=   4.6s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.711 total time=   8.6s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=200;, score=0.713 total time=   8.6s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.712 total time=  21.4s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=5, classifier__n_estimators=500;, score=0.713 total time=  21.6s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.705 total time=   0.8s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=10;, score=0.705 total time=   0.9s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.710 total time=   4.3s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=100;, score=0.713 total time=   4.3s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.711 total time=   8.3s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=200;, score=0.712 total time=   8.6s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.711 total time=  20.3s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500;, score=0.713 total time=  20.6s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.705 total time=   0.8s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=10;, score=0.705 total time=   0.9s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.709 total time=   4.5s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=100;, score=0.710 total time=   4.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.710 total time=   8.7s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=200;, score=0.712 total time=   8.5s\n",
      "[CV 1/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.710 total time=  20.2s\n",
      "[CV 2/2] END classifier__min_samples_leaf=4, classifier__min_samples_split=20, classifier__n_estimators=500;, score=0.711 total time=  21.3s\n",
      "Best Parameters: {'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
      "Best Mean Cross-validated Score: 0.7249665225512476\n"
     ]
    }
   ],
   "source": [
    "best_estimator = grid_search_best_estimator(\n",
    "    pipelines['RandomForestClassifier'],\n",
    "    param_grid=param_grid,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=2,\n",
    "    scoring='f1_micro',\n",
    "    verbose = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_predictions(best_estimator, test_values, 'submission/new_predictions_alt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-b38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
